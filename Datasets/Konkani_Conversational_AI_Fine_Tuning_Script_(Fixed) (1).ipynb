{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Konkani Conversational AI Fine-Tuning Script\n",
        "# ---------------------------------------------\n",
        "# This script demonstrates how to fine-tune a pre-trained transformer model\n",
        "# for conversational tasks in Konkani using an English-Konkani dataset.\n",
        "# It uses the Hugging Face libraries (transformers, datasets) and PyTorch.\n",
        "\n",
        "# Step 1: Install necessary libraries\n",
        "# -----------------------------------\n",
        "# Before running, make sure you have these libraries installed:\n",
        "# pip install torch transformers datasets pandas sentencepiece accelerate\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import (\n",
        "    T5ForConditionalGeneration,\n",
        "    T5Tokenizer,\n",
        "    Seq2SeqTrainingArguments,\n",
        "    Seq2SeqTrainer,\n",
        "    DataCollatorForSeq2Seq,\n",
        ")\n",
        "from datasets import Dataset as HfDataset\n",
        "import os\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "# --- Please edit these variables to match your setup ---\n",
        "\n",
        "# File and Data Configuration\n",
        "FILE_PATH = 'final_dataset.csv'  # <-- IMPORTANT: Change this to the exact path of your CSV file.\n",
        "INPUT_COLUMN = 'ENGLISH'         # <-- The column with the source language (English)\n",
        "TARGET_COLUMN = 'KONKANI'        # <-- The column with the target language (Konkani)\n",
        "\n",
        "# Model Configuration\n",
        "MODEL_NAME = 't5-small'          # We use 't5-small' for a balance of performance and training speed.\n",
        "                                 # For higher quality, consider 't5-base' or 't5-large' (requires more GPU memory).\n",
        "PREFIX = \"chat in konkani: \"     # T5 models are trained with prefixes. This tells the model what task to perform.\n",
        "\n",
        "# Training Configuration\n",
        "OUTPUT_DIR = './konkani_t5_model' # Directory to save the fine-tuned model and tokenizer.\n",
        "EPOCHS = 5                       # Number of times to train on the entire dataset.\n",
        "BATCH_SIZE = 8                   # Number of examples per training step. Adjust based on your GPU memory.\n",
        "MAX_INPUT_LENGTH = 128           # Max length for input tokens.\n",
        "MAX_TARGET_LENGTH = 128          # Max length for output tokens.\n",
        "\n",
        "# --- END OF CONFIGURATION ---\n",
        "\n",
        "\n",
        "def load_and_prepare_data():\n",
        "    \"\"\"\n",
        "    Loads the dataset from the CSV file and prepares it for the model.\n",
        "    It handles potential file errors and formats the data into a\n",
        "    Hugging Face Dataset object.\n",
        "    \"\"\"\n",
        "    print(f\"Attempting to load data from: {FILE_PATH}\")\n",
        "    try:\n",
        "        # Load the dataset using pandas, specifying the encoding\n",
        "        df = pd.read_csv(FILE_PATH, encoding='latin1')\n",
        "\n",
        "        # Verify that the required columns exist\n",
        "        if INPUT_COLUMN not in df.columns or TARGET_COLUMN not in df.columns:\n",
        "            raise ValueError(\n",
        "                f\"CSV must contain '{INPUT_COLUMN}' and '{TARGET_COLUMN}' columns. \"\n",
        "                f\"Found columns: {df.columns.tolist()}\"\n",
        "            )\n",
        "        print(\"Successfully loaded the dataset.\")\n",
        "        print(f\"Dataset has {len(df)} rows.\")\n",
        "\n",
        "        # Drop any rows with missing values in our target columns\n",
        "        df.dropna(subset=[INPUT_COLUMN, TARGET_COLUMN], inplace=True)\n",
        "        df = df.astype(str) # Ensure all data is string type\n",
        "\n",
        "        # Convert the pandas DataFrame to a Hugging Face Dataset object\n",
        "        return HfDataset.from_pandas(df)\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(\"---\")\n",
        "        print(f\"ERROR: The file '{FILE_PATH}' was not found.\")\n",
        "        print(\"Please make sure the file path in the script is correct.\")\n",
        "        print(\"---\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while loading the data: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def preprocess_data(dataset, tokenizer):\n",
        "    \"\"\"\n",
        "    Tokenizes the input and target text. The T5 model requires a specific\n",
        "    prefix to understand the task, which we add here.\n",
        "    \"\"\"\n",
        "    print(\"Preprocessing and tokenizing data...\")\n",
        "\n",
        "    def tokenize_function(examples):\n",
        "        # Prepend the task-specific prefix to the input\n",
        "        inputs = [PREFIX + doc for doc in examples[INPUT_COLUMN]]\n",
        "\n",
        "        # Tokenize the inputs\n",
        "        model_inputs = tokenizer(\n",
        "            inputs,\n",
        "            max_length=MAX_INPUT_LENGTH,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\"\n",
        "        )\n",
        "\n",
        "        # Tokenize the targets (labels)\n",
        "        labels = tokenizer(\n",
        "            text_target=examples[TARGET_COLUMN],\n",
        "            max_length=MAX_TARGET_LENGTH,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\"\n",
        "        )\n",
        "\n",
        "        model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "        return model_inputs\n",
        "\n",
        "    # Apply the tokenization function to the entire dataset\n",
        "    tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
        "    print(\"Data preprocessing complete.\")\n",
        "    return tokenized_dataset\n",
        "\n",
        "\n",
        "def train_model(tokenized_dataset, tokenizer):\n",
        "    \"\"\"\n",
        "    Sets up the model, training arguments, and trainer, then\n",
        "    initiates the fine-tuning process.\n",
        "    \"\"\"\n",
        "    print(\"Setting up the model and trainer...\")\n",
        "\n",
        "    # Load the pre-trained T5 model\n",
        "    model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME)\n",
        "\n",
        "    # Define the training arguments\n",
        "    # These arguments control various aspects of the training run\n",
        "    training_args = Seq2SeqTrainingArguments(\n",
        "        output_dir=OUTPUT_DIR,\n",
        "        num_train_epochs=EPOCHS,\n",
        "        per_device_train_batch_size=BATCH_SIZE,\n",
        "        per_device_eval_batch_size=BATCH_SIZE, # If you add an evaluation set\n",
        "        warmup_steps=500,\n",
        "        weight_decay=0.01,\n",
        "        logging_dir='./logs',\n",
        "        logging_steps=10,\n",
        "        save_total_limit=2, # Only keep the best 2 checkpoints\n",
        "        predict_with_generate=True,\n",
        "        report_to=\"none\", # --- THIS LINE WAS ADDED --- Disables wandb logging\n",
        "    )\n",
        "\n",
        "    # The data collator is responsible for creating batches of data.\n",
        "    # It also handles dynamic padding.\n",
        "    data_collator = DataCollatorForSeq2Seq(\n",
        "        tokenizer=tokenizer,\n",
        "        model=model\n",
        "    )\n",
        "\n",
        "    # Instantiate the trainer\n",
        "    trainer = Seq2SeqTrainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=tokenized_dataset,\n",
        "        # You can add an eval_dataset here for metrics during training\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=data_collator,\n",
        "    )\n",
        "\n",
        "    print(\"--- Starting Model Training ---\")\n",
        "    print(f\"Model: {MODEL_NAME}\")\n",
        "    print(f\"Epochs: {EPOCHS}, Batch Size: {BATCH_SIZE}\")\n",
        "    print(f\"Output will be saved to: {OUTPUT_DIR}\")\n",
        "\n",
        "    # Start the training\n",
        "    trainer.train()\n",
        "\n",
        "    print(\"--- Training Complete ---\")\n",
        "\n",
        "    # Save the final model and tokenizer\n",
        "    print(f\"Saving the fine-tuned model to {OUTPUT_DIR}...\")\n",
        "    trainer.save_model(OUTPUT_DIR)\n",
        "    tokenizer.save_pretrained(OUTPUT_DIR)\n",
        "    print(\"Model saved successfully.\")\n",
        "\n",
        "\n",
        "def run_conversation_loop():\n",
        "    \"\"\"\n",
        "    Loads the fine-tuned model from disk and starts a conversational\n",
        "    loop to interact with it.\n",
        "    \"\"\"\n",
        "    print(\"\\n--- Starting Konkani Chatbot ---\")\n",
        "\n",
        "    # Check if the model directory exists\n",
        "    if not os.path.exists(OUTPUT_DIR):\n",
        "        print(f\"Error: Model directory '{OUTPUT_DIR}' not found.\")\n",
        "        print(\"Please train the model first by running the main script.\")\n",
        "        return\n",
        "\n",
        "    print(f\"Loading fine-tuned model from {OUTPUT_DIR}...\")\n",
        "    try:\n",
        "        tokenizer = T5Tokenizer.from_pretrained(OUTPUT_DIR)\n",
        "        model = T5ForConditionalGeneration.from_pretrained(OUTPUT_DIR)\n",
        "        # Move model to GPU if available\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        model.to(device)\n",
        "        print(f\"Model loaded successfully on device: {device}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to load the model: {e}\")\n",
        "        return\n",
        "\n",
        "    print(\"\\nChatbot is ready. Type your message in English.\")\n",
        "    print(\"Type 'exit' or 'quit' to end the conversation.\")\n",
        "    print(\"--------------------------------------------------\")\n",
        "\n",
        "    while True:\n",
        "        english_prompt = input(\"You (English): \")\n",
        "        if english_prompt.lower() in ['exit', 'quit']:\n",
        "            print(\"Bot: Adeus! (Goodbye!)\")\n",
        "            break\n",
        "\n",
        "        # Prepare the input for the model\n",
        "        full_prompt = PREFIX + english_prompt\n",
        "        input_ids = tokenizer.encode(full_prompt, return_tensors='pt').to(device)\n",
        "\n",
        "        # Generate the response from the model\n",
        "        # We use different parameters here to encourage more creative responses\n",
        "        output_ids = model.generate(\n",
        "            input_ids,\n",
        "            max_length=MAX_TARGET_LENGTH,\n",
        "            num_beams=5, # Beam search can produce better results\n",
        "            early_stopping=True,\n",
        "            no_repeat_ngram_size=2 # Prevents the model from repeating itself\n",
        "        )\n",
        "\n",
        "        # Decode the generated tokens into a string\n",
        "        konkani_response = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "\n",
        "        print(f\"Bot (Konkani): {konkani_response}\")\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # This block runs when the script is executed directly\n",
        "\n",
        "    # Ask the user what they want to do\n",
        "    print(\"Welcome to the Konkani AI Model Trainer.\")\n",
        "    print(\"1: Train a new model\")\n",
        "    print(\"2: Chat with an existing model\")\n",
        "    choice = input(\"Please enter your choice (1 or 2): \")\n",
        "\n",
        "    if choice == '1':\n",
        "        # --- Main Training Pipeline ---\n",
        "        # 1. Load data\n",
        "        raw_dataset = load_and_prepare_data()\n",
        "\n",
        "        if raw_dataset:\n",
        "            # 2. Initialize tokenizer\n",
        "            tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "            # 3. Preprocess and tokenize data\n",
        "            tokenized_dataset = preprocess_data(raw_dataset, tokenizer)\n",
        "\n",
        "            # 4. Train the model\n",
        "            train_model(tokenized_dataset, tokenizer)\n",
        "\n",
        "            # 5. Offer to chat with the newly trained model\n",
        "            chat_now = input(\"Training complete. Would you like to chat with the new model? (yes/no): \")\n",
        "            if chat_now.lower() == 'yes':\n",
        "                run_conversation_loop()\n",
        "\n",
        "    elif choice == '2':\n",
        "        # --- Run Inference ---\n",
        "        run_conversation_loop()\n",
        "    else:\n",
        "        print(\"Invalid choice. Please run the script again and enter 1 or 2.\")\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the Konkani AI Model Trainer.\n",
            "1: Train a new model\n",
            "2: Chat with an existing model\n",
            "Please enter your choice (1 or 2): 1\n",
            "Attempting to load data from: final_dataset.csv\n",
            "Successfully loaded the dataset.\n",
            "Dataset has 70158 rows.\n",
            "Preprocessing and tokenizing data...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/70158 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c2a595dac27c4b7892206dcb45ee0b69"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data preprocessing complete.\n",
            "Setting up the model and trainer...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-10-3216896730.py:156: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Seq2SeqTrainer(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Model Training ---\n",
            "Model: t5-small\n",
            "Epochs: 5, Batch Size: 8\n",
            "Output will be saved to: ./konkani_t5_model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2' max='43850' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [    2/43850 : < :, Epoch 0.00/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422,
          "referenced_widgets": [
            "c2a595dac27c4b7892206dcb45ee0b69",
            "38668634b5314ea096111a6c3df115af",
            "1e86eae868164e46a4bd76f5ba1b19b8",
            "538f34da91264129801712a018588501",
            "a75ca60809764dc19eb68419d772b7f5",
            "8025e28425864102aca58efed8132615",
            "45b6a246c46d4e13b2c92248698cf3ee",
            "ed35b2af3f94494987dec32d055ecba3",
            "a999269eb0354b3487076d75483a908d",
            "8f12e327ee61493097376a00dc353ea1",
            "ad7167ccc96b497194e8f43c5c24e916"
          ]
        },
        "id": "rig9nxnzqVmk",
        "outputId": "652822d8-bdbf-4bae-d1f7-9d67073b36ec"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c2a595dac27c4b7892206dcb45ee0b69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_38668634b5314ea096111a6c3df115af",
              "IPY_MODEL_1e86eae868164e46a4bd76f5ba1b19b8",
              "IPY_MODEL_538f34da91264129801712a018588501"
            ],
            "layout": "IPY_MODEL_a75ca60809764dc19eb68419d772b7f5"
          }
        },
        "38668634b5314ea096111a6c3df115af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8025e28425864102aca58efed8132615",
            "placeholder": "​",
            "style": "IPY_MODEL_45b6a246c46d4e13b2c92248698cf3ee",
            "value": "Map: 100%"
          }
        },
        "1e86eae868164e46a4bd76f5ba1b19b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed35b2af3f94494987dec32d055ecba3",
            "max": 70158,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a999269eb0354b3487076d75483a908d",
            "value": 70158
          }
        },
        "538f34da91264129801712a018588501": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f12e327ee61493097376a00dc353ea1",
            "placeholder": "​",
            "style": "IPY_MODEL_ad7167ccc96b497194e8f43c5c24e916",
            "value": " 70158/70158 [00:33&lt;00:00, 1667.27 examples/s]"
          }
        },
        "a75ca60809764dc19eb68419d772b7f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8025e28425864102aca58efed8132615": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45b6a246c46d4e13b2c92248698cf3ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed35b2af3f94494987dec32d055ecba3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a999269eb0354b3487076d75483a908d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8f12e327ee61493097376a00dc353ea1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad7167ccc96b497194e8f43c5c24e916": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}